{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30301,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-12T21:58:08.791914Z","iopub.execute_input":"2023-07-12T21:58:08.792427Z","iopub.status.idle":"2023-07-12T21:58:08.825602Z","shell.execute_reply.started":"2023-07-12T21:58:08.792331Z","shell.execute_reply":"2023-07-12T21:58:08.824297Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Here we load the datasets","metadata":{}},{"cell_type":"code","source":"df_training = pd.read_csv('/kaggle/input/titanic/train.csv')\ndf_test = pd.read_csv('/kaggle/input/titanic/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:56:48.618655Z","iopub.execute_input":"2022-12-11T22:56:48.619435Z","iopub.status.idle":"2022-12-11T22:56:48.647552Z","shell.execute_reply.started":"2022-12-11T22:56:48.619390Z","shell.execute_reply":"2022-12-11T22:56:48.646708Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"df_training","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:56:48.649336Z","iopub.execute_input":"2022-12-11T22:56:48.649692Z","iopub.status.idle":"2022-12-11T22:56:48.679847Z","shell.execute_reply.started":"2022-12-11T22:56:48.649660Z","shell.execute_reply":"2022-12-11T22:56:48.678535Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"     PassengerId  Survived  Pclass  \\\n0              1         0       3   \n1              2         1       1   \n2              3         1       3   \n3              4         1       1   \n4              5         0       3   \n..           ...       ...     ...   \n886          887         0       2   \n887          888         1       1   \n888          889         0       3   \n889          890         1       1   \n890          891         0       3   \n\n                                                  Name     Sex   Age  SibSp  \\\n0                              Braund, Mr. Owen Harris    male  22.0      1   \n1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                               Heikkinen, Miss. Laina  female  26.0      0   \n3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                             Allen, Mr. William Henry    male  35.0      0   \n..                                                 ...     ...   ...    ...   \n886                              Montvila, Rev. Juozas    male  27.0      0   \n887                       Graham, Miss. Margaret Edith  female  19.0      0   \n888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n889                              Behr, Mr. Karl Howell    male  26.0      0   \n890                                Dooley, Mr. Patrick    male  32.0      0   \n\n     Parch            Ticket     Fare Cabin Embarked  \n0        0         A/5 21171   7.2500   NaN        S  \n1        0          PC 17599  71.2833   C85        C  \n2        0  STON/O2. 3101282   7.9250   NaN        S  \n3        0            113803  53.1000  C123        S  \n4        0            373450   8.0500   NaN        S  \n..     ...               ...      ...   ...      ...  \n886      0            211536  13.0000   NaN        S  \n887      0            112053  30.0000   B42        S  \n888      2        W./C. 6607  23.4500   NaN        S  \n889      0            111369  30.0000  C148        C  \n890      0            370376   7.7500   NaN        Q  \n\n[891 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>887</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Montvila, Rev. Juozas</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>211536</td>\n      <td>13.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>888</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Graham, Miss. Margaret Edith</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>112053</td>\n      <td>30.0000</td>\n      <td>B42</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>889</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2</td>\n      <td>W./C. 6607</td>\n      <td>23.4500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>890</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Behr, Mr. Karl Howell</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>111369</td>\n      <td>30.0000</td>\n      <td>C148</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>891</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Dooley, Mr. Patrick</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>370376</td>\n      <td>7.7500</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n  </tbody>\n</table>\n<p>891 rows × 12 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_test","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:56:48.682367Z","iopub.execute_input":"2022-12-11T22:56:48.682843Z","iopub.status.idle":"2022-12-11T22:56:48.706865Z","shell.execute_reply.started":"2022-12-11T22:56:48.682797Z","shell.execute_reply":"2022-12-11T22:56:48.706069Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"     PassengerId  Pclass                                          Name  \\\n0            892       3                              Kelly, Mr. James   \n1            893       3              Wilkes, Mrs. James (Ellen Needs)   \n2            894       2                     Myles, Mr. Thomas Francis   \n3            895       3                              Wirz, Mr. Albert   \n4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n..           ...     ...                                           ...   \n413         1305       3                            Spector, Mr. Woolf   \n414         1306       1                  Oliva y Ocana, Dona. Fermina   \n415         1307       3                  Saether, Mr. Simon Sivertsen   \n416         1308       3                           Ware, Mr. Frederick   \n417         1309       3                      Peter, Master. Michael J   \n\n        Sex   Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \n0      male  34.5      0      0              330911    7.8292   NaN        Q  \n1    female  47.0      1      0              363272    7.0000   NaN        S  \n2      male  62.0      0      0              240276    9.6875   NaN        Q  \n3      male  27.0      0      0              315154    8.6625   NaN        S  \n4    female  22.0      1      1             3101298   12.2875   NaN        S  \n..      ...   ...    ...    ...                 ...       ...   ...      ...  \n413    male   NaN      0      0           A.5. 3236    8.0500   NaN        S  \n414  female  39.0      0      0            PC 17758  108.9000  C105        C  \n415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n416    male   NaN      0      0              359309    8.0500   NaN        S  \n417    male   NaN      1      1                2668   22.3583   NaN        C  \n\n[418 rows x 11 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>3</td>\n      <td>Kelly, Mr. James</td>\n      <td>male</td>\n      <td>34.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>330911</td>\n      <td>7.8292</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>3</td>\n      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n      <td>female</td>\n      <td>47.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>363272</td>\n      <td>7.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>2</td>\n      <td>Myles, Mr. Thomas Francis</td>\n      <td>male</td>\n      <td>62.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>240276</td>\n      <td>9.6875</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>3</td>\n      <td>Wirz, Mr. Albert</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>315154</td>\n      <td>8.6625</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>3</td>\n      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n      <td>female</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3101298</td>\n      <td>12.2875</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>413</th>\n      <td>1305</td>\n      <td>3</td>\n      <td>Spector, Mr. Woolf</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>A.5. 3236</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>414</th>\n      <td>1306</td>\n      <td>1</td>\n      <td>Oliva y Ocana, Dona. Fermina</td>\n      <td>female</td>\n      <td>39.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>PC 17758</td>\n      <td>108.9000</td>\n      <td>C105</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>415</th>\n      <td>1307</td>\n      <td>3</td>\n      <td>Saether, Mr. Simon Sivertsen</td>\n      <td>male</td>\n      <td>38.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>SOTON/O.Q. 3101262</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>416</th>\n      <td>1308</td>\n      <td>3</td>\n      <td>Ware, Mr. Frederick</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>359309</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>417</th>\n      <td>1309</td>\n      <td>3</td>\n      <td>Peter, Master. Michael J</td>\n      <td>male</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2668</td>\n      <td>22.3583</td>\n      <td>NaN</td>\n      <td>C</td>\n    </tr>\n  </tbody>\n</table>\n<p>418 rows × 11 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Preprocessing of data","metadata":{}},{"cell_type":"markdown","source":"First let's see the number of NaN values in the train dataset","metadata":{}},{"cell_type":"code","source":"#first way to count null values\ndf_training.isna().count()","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:56:48.708995Z","iopub.execute_input":"2022-12-11T22:56:48.709539Z","iopub.status.idle":"2022-12-11T22:56:48.719816Z","shell.execute_reply.started":"2022-12-11T22:56:48.709506Z","shell.execute_reply":"2022-12-11T22:56:48.718738Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"PassengerId    891\nSurvived       891\nPclass         891\nName           891\nSex            891\nAge            891\nSibSp          891\nParch          891\nTicket         891\nFare           891\nCabin          891\nEmbarked       891\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"#Second way to count null values\ndf_training.info()","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:56:48.721378Z","iopub.execute_input":"2022-12-11T22:56:48.722595Z","iopub.status.idle":"2022-12-11T22:56:48.738089Z","shell.execute_reply.started":"2022-12-11T22:56:48.722552Z","shell.execute_reply":"2022-12-11T22:56:48.736982Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"df_test.info()","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:56:48.739961Z","iopub.execute_input":"2022-12-11T22:56:48.740419Z","iopub.status.idle":"2022-12-11T22:56:48.755773Z","shell.execute_reply.started":"2022-12-11T22:56:48.740376Z","shell.execute_reply":"2022-12-11T22:56:48.754527Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 418 entries, 0 to 417\nData columns (total 11 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  418 non-null    int64  \n 1   Pclass       418 non-null    int64  \n 2   Name         418 non-null    object \n 3   Sex          418 non-null    object \n 4   Age          332 non-null    float64\n 5   SibSp        418 non-null    int64  \n 6   Parch        418 non-null    int64  \n 7   Ticket       418 non-null    object \n 8   Fare         417 non-null    float64\n 9   Cabin        91 non-null     object \n 10  Embarked     418 non-null    object \ndtypes: float64(2), int64(4), object(5)\nmemory usage: 36.0+ KB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"From the previous output of the cell we can see that cabin columns have a lot of null-values, so we drop this column. We can also see that the column \"Age\" have 177 Missing values so we're gonna fill thowse values with IterativeImputer","metadata":{}},{"cell_type":"markdown","source":"## One-Hot-Encode the data ","metadata":{}},{"cell_type":"code","source":"#Here we one-hot-encode the columns sex and embarked\ndf_training = pd.get_dummies(df_training, columns = ['Sex','Embarked'])\ndf_test = pd.get_dummies(df_test, columns = ['Sex','Embarked'])\n","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:56:48.757970Z","iopub.execute_input":"2022-12-11T22:56:48.758407Z","iopub.status.idle":"2022-12-11T22:56:48.775082Z","shell.execute_reply.started":"2022-12-11T22:56:48.758362Z","shell.execute_reply":"2022-12-11T22:56:48.773839Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"The features Cabin,Name and ticket are dropped because does not apport to a model prediction ()","metadata":{}},{"cell_type":"code","source":"df_training.drop('Cabin', inplace=True, axis=1)\ndf_training.drop('Name', inplace=True, axis=1)\ndf_training.drop('Ticket', inplace=True, axis=1)\ndf_training.drop('PassengerId', inplace=True, axis=1)\n\nids = df_test['PassengerId']\ndf_test.drop('Cabin', inplace=True, axis=1)\ndf_test.drop('Name', inplace=True, axis=1)\ndf_test.drop('Ticket', inplace=True, axis=1)\ndf_test.drop('PassengerId', inplace=True, axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:56:48.776774Z","iopub.execute_input":"2022-12-11T22:56:48.777618Z","iopub.status.idle":"2022-12-11T22:56:48.794745Z","shell.execute_reply.started":"2022-12-11T22:56:48.777559Z","shell.execute_reply":"2022-12-11T22:56:48.793633Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"markdown","source":"# ","metadata":{}},{"cell_type":"code","source":"from sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\n#df_training = df_training[df_training['Age'].notna()]\n#df_training.info()\n\nimpute_it = IterativeImputer()\nv = impute_it.fit_transform(df_training)\nv2 = impute_it.fit_transform(df_test)\n\ndf_training = pd.DataFrame(v, columns=df_training.columns)\ndf_test = pd.DataFrame(v2, columns=df_test.columns)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:56:48.796050Z","iopub.execute_input":"2022-12-11T22:56:48.796678Z","iopub.status.idle":"2022-12-11T22:56:48.876218Z","shell.execute_reply.started":"2022-12-11T22:56:48.796646Z","shell.execute_reply":"2022-12-11T22:56:48.875306Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX = df_training.loc[:, df_training.columns != 'Survived']\nY = df_training['Survived']\n\nX_train, X_test, y_train, y_test = train_test_split(\n X, Y, random_state=0)\n","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:56:48.879235Z","iopub.execute_input":"2022-12-11T22:56:48.879605Z","iopub.status.idle":"2022-12-11T22:56:48.888300Z","shell.execute_reply.started":"2022-12-11T22:56:48.879572Z","shell.execute_reply":"2022-12-11T22:56:48.887007Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"from sklearn import tree\nmodel = tree.DecisionTreeClassifier()\nmodel = model.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:56:48.890084Z","iopub.execute_input":"2022-12-11T22:56:48.890502Z","iopub.status.idle":"2022-12-11T22:56:48.904771Z","shell.execute_reply.started":"2022-12-11T22:56:48.890462Z","shell.execute_reply":"2022-12-11T22:56:48.903396Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"from sklearn import linear_model\nmodel_2 = linear_model.LinearRegression()\nmodel_4 = linear_model.BayesianRidge()\nmodel_2 = model_2.fit(X_train, y_train)\nmodel_4 = model_4.fit(X_train, y_train)\n","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:56:48.906283Z","iopub.execute_input":"2022-12-11T22:56:48.906648Z","iopub.status.idle":"2022-12-11T22:56:48.918403Z","shell.execute_reply.started":"2022-12-11T22:56:48.906616Z","shell.execute_reply":"2022-12-11T22:56:48.917047Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"from sklearn import svm\nmodel_3 = svm.SVC()\nmodel_3 = model_3.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:56:48.920726Z","iopub.execute_input":"2022-12-11T22:56:48.921501Z","iopub.status.idle":"2022-12-11T22:56:48.949942Z","shell.execute_reply.started":"2022-12-11T22:56:48.921436Z","shell.execute_reply":"2022-12-11T22:56:48.948727Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nmodel_5 = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)\nmodel_5.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:56:48.951376Z","iopub.execute_input":"2022-12-11T22:56:48.951896Z","iopub.status.idle":"2022-12-11T22:56:48.967777Z","shell.execute_reply.started":"2022-12-11T22:56:48.951840Z","shell.execute_reply":"2022-12-11T22:56:48.966622Z"},"trusted":true},"execution_count":79,"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,\n              solver='lbfgs')"},"metadata":{}}]},{"cell_type":"code","source":"score_1 = model.score(X_test, y_test, sample_weight=None)\nscore_2 = model_2.score(X_test, y_test, sample_weight=None)\nscore_3 = model_3.score(X_test, y_test, sample_weight=None)\nscore_4 = model_4.score(X_test, y_test, sample_weight=None)\nscore_5 = model_5.score(X_test, y_test, sample_weight=None)\n\n\nprint('Score of decision tree: '+ str(score_1))\nprint('Score of linear_regresion '+ str(score_2))\nprint('Score of SVM '+ str(score_3))\nprint('Score of BayesianRidge '+ str(score_4))\nprint('Score of Neural Network Model '+ str(score_5))\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-12-11T22:56:48.969147Z","iopub.execute_input":"2022-12-11T22:56:48.969940Z","iopub.status.idle":"2022-12-11T22:56:48.994403Z","shell.execute_reply.started":"2022-12-11T22:56:48.969897Z","shell.execute_reply":"2022-12-11T22:56:48.993406Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"Score of decision tree: 0.7443946188340808\nScore of linear_regresion 0.41730561008186273\nScore of SVM 0.7219730941704036\nScore of BayesianRidge 0.4172379458122767\nScore of Neural Network Model 0.6233183856502242\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Making predictions","metadata":{}},{"cell_type":"code","source":"#model.predict(df_test)\ndata = {'PassengerId': ids,\n        'Survived': model.predict(df_test) }\npredicciones = pd.DataFrame(data).set_index('PassengerId')\n#filepath = Path('kaggle/working/out.csv')  \npredicciones.to_csv('/kaggle/working/out.csv')\npredicciones","metadata":{"execution":{"iopub.status.busy":"2022-12-11T23:09:53.969523Z","iopub.execute_input":"2022-12-11T23:09:53.970646Z","iopub.status.idle":"2022-12-11T23:09:53.991705Z","shell.execute_reply.started":"2022-12-11T23:09:53.970593Z","shell.execute_reply":"2022-12-11T23:09:53.990510Z"},"trusted":true},"execution_count":91,"outputs":[{"execution_count":91,"output_type":"execute_result","data":{"text/plain":"             Survived\nPassengerId          \n892               0.0\n893               0.0\n894               0.0\n895               1.0\n896               1.0\n...               ...\n1305              0.0\n1306              1.0\n1307              0.0\n1308              0.0\n1309              1.0\n\n[418 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Survived</th>\n    </tr>\n    <tr>\n      <th>PassengerId</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>892</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>893</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>894</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>895</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>896</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1305</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1306</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1307</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1308</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1309</th>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>418 rows × 1 columns</p>\n</div>"},"metadata":{}}]}]}